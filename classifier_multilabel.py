"""
–ú—É–ª—å—Ç–∏–º–µ—Ç–æ—á–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ + BERT
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: ads, crypto, scam, casino
"""
import logging
from typing import Dict, Optional, TYPE_CHECKING

logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å transformers
if TYPE_CHECKING:
    from transformers import pipeline as _pipeline  # type: ignore[import-not-found]

try:
    from transformers import pipeline  # type: ignore[import-not-found]
    HAS_TRANSFORMERS = True
except Exception:
    HAS_TRANSFORMERS = False
    logger.warning("transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, BERT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ config.py
try:
    from config import RUBERT_MODEL, USE_RUBERT
except Exception:
    RUBERT_MODEL = 'cointegrated/rubert-tiny2'
    USE_RUBERT = True

# –ò–º–ø–æ—Ä—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
from spam_rules_multilabel import (
    heuristic_multilabel_score,
    heuristic_multilabel_predict
)

# BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)
bert_classifier = None
bert_pipeline_type = None  # 'zero-shot-classification' –∏–ª–∏ 'text-classification'

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
LABELS = ["ads", "crypto", "scam", "casino"]

# –ü–æ—Ä–æ–≥–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_THRESHOLDS = {
    "ads": 0.4,
    "crypto": 0.5,
    "scam": 0.5,
    "casino": 0.5
}


def _load_bert_classifier():
    """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞."""
    global bert_classifier, bert_pipeline_type
    
    if bert_classifier is not None:
        return bert_classifier, bert_pipeline_type
    
    if not HAS_TRANSFORMERS or not USE_RUBERT:
        logger.debug("BERT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (HAS_TRANSFORMERS=%s, USE_RUBERT=%s)", 
                    HAS_TRANSFORMERS, USE_RUBERT)
        return None, None
    
    try:
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: %s", RUBERT_MODEL)
        # –ü—Ä–æ–±—É–µ–º zero-shot classification (–ª—É—á—à–µ –¥–ª—è –º—É–ª—å—Ç–∏–º–µ—Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
        try:
            bert_classifier = pipeline(
                'zero-shot-classification',
                model=RUBERT_MODEL,
                device=-1  # CPU
            )
            bert_pipeline_type = 'zero-shot-classification'
            logger.info("‚úì BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω (zero-shot-classification)")
        except Exception as e1:
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º text-classification –µ—Å–ª–∏ zero-shot –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            logger.warning("zero-shot-classification –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: %s", str(e1))
            logger.info("–ü—Ä–æ–±—É–µ–º text-classification...")
            try:
                bert_classifier = pipeline(
                    'text-classification',
                    model=RUBERT_MODEL,
                    device=-1  # CPU
                )
                bert_pipeline_type = 'text-classification'
                logger.info("‚úì BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω (text-classification)")
            except Exception as e2:
                logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: %s", str(e2))
                return None, None
        
        return bert_classifier, bert_pipeline_type
    except Exception as e:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å BERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: %s", str(e))
        return None, None


def classify_with_bert(text: str, candidate_labels: list = None) -> Dict[str, float]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ BERT (zero-shot –∏–ª–∏ text-classification).
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        candidate_labels: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: LABELS)
    
    Returns:
        Dict —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (0.0 - 1.0)
    """
    if candidate_labels is None:
        candidate_labels = LABELS
    
    classifier, pipeline_type = _load_bert_classifier()
    if classifier is None:
        return {label: 0.0 for label in candidate_labels}
    
    try:
        if pipeline_type == 'zero-shot-classification':
            # Zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            result = classifier(text[:512], candidate_labels, multi_label=True)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å
            scores = {}
            if isinstance(result, dict) and "labels" in result and "scores" in result:
                for label, score in zip(result["labels"], result["scores"]):
                    scores[label] = float(score)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            for label in candidate_labels:
                if label not in scores:
                    scores[label] = 0.0
            
            return scores
        else:
            # –î–ª—è text-classification –º–æ–¥–µ–ª–∏ (rubert-tiny2) –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∏ –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –º–µ—Ç–∫–∞–º
            result = classifier(text[:512])
            
            # text-classification –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å –æ–¥–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            if isinstance(result, list) and len(result) > 0:
                label = result[0].get('label', '').lower()
                score = result[0].get('score', 0.0)
                
                # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –º–µ—Ç–∫—É —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
                scores = {cat: 0.0 for cat in candidate_labels}
                
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –º–µ—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç "spam" –∏–ª–∏ "positive", —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º score
                if 'spam' in label or 'positive' in label or '1' in label:
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ –∫–∞–∫ —Å–ø–∞–º, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º score —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ
                    # (—ç—Ç–æ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –ª—É—á—à–µ —á–µ–º –Ω–∏—á–µ–≥–æ)
                    for cat in candidate_labels:
                        scores[cat] = score * 0.5  # –£–º–µ—Ä–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                else:
                    # –ï—Å–ª–∏ –Ω–µ —Å–ø–∞–º, –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–ª—É—á–∞—é—Ç –Ω–∏–∑–∫—É—é –æ—Ü–µ–Ω–∫—É
                    for cat in candidate_labels:
                        scores[cat] = (1.0 - score) * 0.1
                
                return scores
            else:
                return {label: 0.0 for label in candidate_labels}
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ BERT: %s", str(e))
        return {label: 0.0 for label in candidate_labels}


def classify_multilabel(
    text: str,
    use_heuristics: bool = True,
    use_bert: bool = True,
    thresholds: Optional[Dict[str, float]] = None
) -> Dict:
    """
    –ú—É–ª—å—Ç–∏–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        use_heuristics: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–≤—Ä–∏—Å—Ç–∏–∫—É
        use_bert: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å BERT
        thresholds: –ü–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    
    Returns:
        Dict —Å –∫–ª—é—á–∞–º–∏:
            - "scores": Dict[str, float] - –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            - "predictions": Dict[str, int] - –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (0/1)
            - "methods": Dict[str, str] - –∫–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å
    """
    if not text:
        return {
            "scores": {label: 0.0 for label in LABELS},
            "predictions": {label: 0 for label in LABELS},
            "methods": {"heuristics": "skipped", "bert": "skipped"}
        }
    
    if thresholds is None:
        thresholds = DEFAULT_THRESHOLDS.copy()
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –æ—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
    heuristic_scores = {}
    if use_heuristics:
        try:
            heuristic_scores = heuristic_multilabel_score(text)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏: %s", str(e))
            heuristic_scores = {label: 0.0 for label in LABELS}
    else:
        heuristic_scores = {label: 0.0 for label in LABELS}
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –æ—Ç BERT
    bert_scores = {}
    if use_bert:
        try:
            bert_scores = classify_with_bert(text)
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ BERT: %s", str(e))
            bert_scores = {label: 0.0 for label in LABELS}
    else:
        bert_scores = {label: 0.0 for label in LABELS}
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ü–µ–Ω–∫–∏ (—Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ)
    final_scores = {}
    methods_used = {}
    
    for label in LABELS:
        h_score = heuristic_scores.get(label, 0.0)
        b_score = bert_scores.get(label, 0.0)
        
        # –ï—Å–ª–∏ –æ–±–∞ –º–µ—Ç–æ–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã, –±–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ
        if use_heuristics and use_bert and h_score > 0 and b_score > 0:
            final_scores[label] = (h_score + b_score) / 2.0
            methods_used[label] = "heuristics+bert"
        elif use_heuristics and h_score > 0:
            final_scores[label] = h_score
            methods_used[label] = "heuristics"
        elif use_bert and b_score > 0:
            final_scores[label] = b_score
            methods_used[label] = "bert"
        else:
            final_scores[label] = 0.0
            methods_used[label] = "none"
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    predictions = {}
    for label in LABELS:
        predictions[label] = 1 if final_scores[label] >= thresholds.get(label, 0.4) else 0
    
    return {
        "scores": final_scores,
        "predictions": predictions,
        "methods": methods_used,
        "heuristic_scores": heuristic_scores,
        "bert_scores": bert_scores
    }


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (–µ–¥–∏–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ø–∞–º–∞)
def classify_text(text: str) -> dict:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–¥–∏–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å–ø–∞–º–∞.
    """
    result = classify_multilabel(text, use_heuristics=True, use_bert=True)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É —Å–ø–∞–º–∞ (–º–∞–∫—Å–∏–º—É–º –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
    max_score = max(result["scores"].values())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º 1
    is_spam = any(result["predictions"].values())
    
    return {
        "is_spam": is_spam,
        "score": max_score,
        "reason": f"multilabel_max={max_score:.3f}",
        "categories": result["predictions"]
    }


if __name__ == "__main__":
    # –¢–µ—Å—Ç—ã
    test_texts = [
        "üî• –£–°–ü–ï–ô –ó–ê–ë–†–ê–¢–¨! –ú–µ—Å—Ç –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ. –ú–æ—è —Å–µ–∫—Ä–µ—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è p2p –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ –≤ –∑–∞–∫—Ä–µ–ø–µ: t.me/link",
        "–ù–æ–≤–æ–µ –∫–∞–∑–∏–Ω–æ —Å –±–æ–Ω—É—Å–æ–º –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é! –§—Ä–∏—Å–ø–∏–Ω—ã –∏ –¥–∂–µ–∫–ø–æ—Ç –∂–¥—É—Ç –≤–∞—Å!",
        "–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Ö–æ–¥ –±–µ–∑ —Ä–∏—Å–∫–∞! –°—Ö–µ–º–∞ –∑–∞—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∫—Ä–∏–ø—Ç–µ. –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–Ω—å–≥–∏!",
        "–û–±—ã—á–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å –æ —Å–æ–±—ã—Ç–∏—è—Ö –≤ –≥–æ—Ä–æ–¥–µ. –ù–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ."
    ]
    
    for text in test_texts:
        print(f"\n{'='*60}")
        print(f"–¢–µ–∫—Å—Ç: {text[:80]}...")
        result = classify_multilabel(text)
        print(f"–û—Ü–µ–Ω–∫–∏: {result['scores']}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {result['predictions']}")
        print(f"–ú–µ—Ç–æ–¥—ã: {result['methods']}")
