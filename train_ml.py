"""–û–±—É—á–µ–Ω–∏–µ ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∞–º–∞ –≤ Telegram –ø–æ—Å—Ç–∞—Ö."""
import pandas as pd
import joblib
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix

DATA_DIR = Path(__file__).parent / "data"
MODELS_DIR = Path(__file__).parent / "models"
LABELED_CSV_FILE = DATA_DIR / "labeled.csv"
MODEL_FILE = MODELS_DIR / "spam_ml.pkl"

MODELS_DIR.mkdir(exist_ok=True)


def main():
    """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ø–∞–º–∞."""
    print("=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï ML –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –°–ü–ê–ú–ê")
    print("=" * 60)
    
    if not LABELED_CSV_FILE.exists():
        print(f"‚ùå –§–∞–π–ª {LABELED_CSV_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–º–µ—Ç—å—Ç–µ –¥–∞–Ω–Ω—ã–µ:")
        print("  python label_data.py")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {LABELED_CSV_FILE}...")
    try:
        df = pd.read_csv(LABELED_CSV_FILE)
        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    label_counts = df["label"].value_counts()
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    print(f"  –°–ø–∞–º (1): {label_counts.get(1, 0)}")
    print(f"  –ù–µ —Å–ø–∞–º (0): {label_counts.get(0, 0)}")
    
    if len(label_counts) < 2:
        print("‚ùå –ù—É–∂–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –æ–±–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤ (0 –∏ 1)!")
        return
    
    if len(df) < 50:
        print("‚ö† –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 300-500 –ø—Ä–∏–º–µ—Ä–æ–≤.")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        df["text"],
        df["label"],
        test_size=0.2,
        stratify=df["label"],
        random_state=42
    )
    
    print(f"\nüîÄ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  Train: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"  Test: {len(X_test)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º pipeline
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ pipeline (TF-IDF + Logistic Regression)...")
    pipeline = Pipeline([
        ("tfidf", TfidfVectorizer(
            ngram_range=(1, 2),  # –£–Ω–∏–≥—Ä–∞–º–º—ã –∏ –±–∏–≥—Ä–∞–º–º—ã
            min_df=3,  # –ú–∏–Ω–∏–º—É–º 3 –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤–∞
            max_df=0.9,  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
            max_features=10000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        )),
        ("clf", LogisticRegression(
            max_iter=1000,
            class_weight="balanced",  # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã
            random_state=42
        ))
    ])
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    pipeline.fit(X_train, y_train)
    print("‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    print("\nüìà –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:")
    y_pred = pipeline.predict(X_test)
    
    print("\n" + classification_report(y_test, y_pred, target_names=["–ù–µ —Å–ø–∞–º", "–°–ø–∞–º"]))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    print("\nüìä Confusion Matrix:")
    print(f"                –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
    print(f"              –ù–µ —Å–ø–∞–º  –°–ø–∞–º")
    print(f"–†–µ–∞–ª—å–Ω–æ –ù–µ —Å–ø–∞–º   {cm[0][0]:4d}   {cm[0][1]:4d}")
    print(f"        –°–ø–∞–º       {cm[1][0]:4d}   {cm[1][1]:4d}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import f1_score, precision_score, recall_score
    f1 = f1_score(y_test, y_pred, pos_label=1)
    precision = precision_score(y_test, y_pred, pos_label=1)
    recall = recall_score(y_test, y_pred, pos_label=1)
    
    print(f"\nüéØ –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–∫–ª–∞—Å—Å '–°–ø–∞–º'):")
    print(f"  F1-score: {f1:.3f}")
    print(f"  Precision: {precision:.3f}")
    print(f"  Recall: {recall:.3f}")
    
    if f1 < 0.8:
        print("\n‚ö† F1-score < 0.8. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —É–ª—É—á—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É.")
    else:
        print("\n‚úì F1-score >= 0.8. –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {MODEL_FILE}...")
    joblib.dump(pipeline, MODEL_FILE)
    print("‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    
    print("\n" + "=" * 60)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–ú–æ–¥–µ–ª—å: {MODEL_FILE}")
    print("=" * 60)


if __name__ == "__main__":
    main()

