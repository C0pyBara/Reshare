"""–û–±—É—á–µ–Ω–∏–µ multilabel ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–ø–∞–º–∞."""
import pandas as pd
import joblib
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import StandardScaler

from telegram_features import MetaFeatureExtractor

DATA_DIR = Path(__file__).parent / "data"
MODELS_DIR = Path(__file__).parent / "models"
LABELED_CSV_FILE = DATA_DIR / "labeled_multilabel.csv"
MODEL_FILE = MODELS_DIR / "spam_ml_multilabel.pkl"

MODELS_DIR.mkdir(exist_ok=True)

LABELS = ["ads", "crypto", "scam", "casino"]

# –ü–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
THRESHOLDS = {
    "ads": 0.4,
    "crypto": 0.4,
    "scam": 0.3,  # –ù–∏–∂–µ –ø–æ—Ä–æ–≥ –¥–ª—è scam (–≤–∞–∂–Ω–µ–µ recall)
    "casino": 0.4
}


def main():
    """–û–±—É—á–∞–µ—Ç multilabel ML –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ø–∞–º–∞."""
    print("=" * 70)
    print("–û–ë–£–ß–ï–ù–ò–ï MULTILABEL ML –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê")
    print("=" * 70)
    
    if not LABELED_CSV_FILE.exists():
        print(f"‚ùå –§–∞–π–ª {LABELED_CSV_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–º–µ—Ç—å—Ç–µ –¥–∞–Ω–Ω—ã–µ:")
        print("  python label_data_ml.py")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {LABELED_CSV_FILE}...")
    try:
        df = pd.read_csv(LABELED_CSV_FILE)
        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_cols = ["text"] + LABELS
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫:")
    for label in LABELS:
        count = df[label].sum()
        pct = (count / len(df)) * 100
        print(f"  {label:8s}: {count:4d} ({pct:5.1f}%)")
    
    if len(df) < 100:
        print("‚ö† –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 300-500 –ø—Ä–∏–º–µ—Ä–æ–≤.")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X = df["text"].fillna("")
    y = df[LABELS].values
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=None  # –î–ª—è multilabel stratify —Å–ª–æ–∂–Ω–µ–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    )
    
    print(f"\nüîÄ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  Train: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"  Test: {len(X_test)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º pipeline —Å FeatureUnion (TF-IDF + –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏)
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ pipeline (TF-IDF + Meta Features + OneVsRest LR)...")
    
    # Feature Union: –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_union = FeatureUnion([
        ("tfidf", TfidfVectorizer(
            ngram_range=(1, 2),
            min_df=3,
            max_df=0.9,
            max_features=10000
        )),
        ("meta", Pipeline([
            ("meta_extractor", MetaFeatureExtractor()),
            ("scaler", StandardScaler())
        ]))
    ])
    
    # OneVsRest –¥–ª—è multilabel –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    pipeline = Pipeline([
        ("features", feature_union),
        ("clf", OneVsRestClassifier(
            LogisticRegression(
                max_iter=2000,
                class_weight="balanced",
                random_state=42
            )
        ))
    ])
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    pipeline.fit(X_train, y_train)
    print("‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    # –î–ª—è OneVsRestClassifier predict_proba –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–∞—Å—Å–∏–≤–æ–≤
    # –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ - —ç—Ç–æ –º–∞—Å—Å–∏–≤ [P(0), P(1)] –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –º–µ—Ç–∫–∏
    proba_list = pipeline.predict_proba(X_test)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: –º–∞—Å—Å–∏–≤ (n_samples, n_labels) —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ P(1)
    n_samples = len(X_test)
    y_pred_proba = np.zeros((n_samples, len(LABELS)))
    
    if isinstance(proba_list, list) and len(proba_list) == len(LABELS):
        for i in range(len(LABELS)):
            class_proba = proba_list[i]  # –ú–∞—Å—Å–∏–≤ (n_samples, 2)
            if isinstance(class_proba, np.ndarray) and class_proba.ndim == 2:
                y_pred_proba[:, i] = class_proba[:, 1]  # P(label=1)
            else:
                y_pred_proba[:, i] = 0.5  # Fallback
    else:
        # Fallback - –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ —ç—Ç–æ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        y_pred_proba = np.array(proba_list)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    y_pred = np.zeros_like(y_test)
    for i, label in enumerate(LABELS):
        threshold = THRESHOLDS[label]
        y_pred[:, i] = (y_pred_proba[:, i] >= threshold).astype(int)
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    print("\nüìà –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:")
    print("\n" + classification_report(
        y_test, y_pred, 
        target_names=LABELS,
        zero_division=0
    ))
    
    # Micro –∏ Macro F1
    micro_f1 = f1_score(y_test, y_pred, average='micro', zero_division=0)
    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)
    
    print(f"\nüéØ –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"  Micro F1: {micro_f1:.3f}")
    print(f"  Macro F1: {macro_f1:.3f}")
    
    # F1 –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É
    print(f"\nüìä F1-score –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    for i, label in enumerate(LABELS):
        f1 = f1_score(y_test[:, i], y_pred[:, i], zero_division=0)
        print(f"  {label:8s}: {f1:.3f}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º production-–º–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import precision_score, recall_score
    
    print(f"\nüéØ Production –º–µ—Ç—Ä–∏–∫–∏:")
    production_metrics = {
        "ads": {"recall": 0.90, "precision": 0.85},
        "crypto": {"recall": 0.85, "precision": 0.80},
        "scam": {"recall": 0.95, "precision": 0.75},  # –î–ª—è scam recall –≤–∞–∂–Ω–µ–µ
        "casino": {"recall": 0.90, "precision": 0.85}
    }
    
    all_ok = True
    for i, label in enumerate(LABELS):
        recall = recall_score(y_test[:, i], y_pred[:, i], zero_division=0)
        precision = precision_score(y_test[:, i], y_pred[:, i], zero_division=0)
        target_recall = production_metrics[label]["recall"]
        target_precision = production_metrics[label]["precision"]
        
        recall_ok = recall >= target_recall
        precision_ok = precision >= target_precision
        
        status = "‚úì" if (recall_ok and precision_ok) else "‚ö†"
        if not (recall_ok and precision_ok):
            all_ok = False
        
        print(f"  {status} {label:8s}: recall={recall:.3f} (‚â•{target_recall}), precision={precision:.3f} (‚â•{target_precision})")
    
    if all_ok:
        print("\n‚úÖ –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç production —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º!")
    else:
        print("\n‚ö† –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∏–∂–µ —Ü–µ–ª–µ–≤—ã—Ö. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:")
        print("  - –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
        print("  - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ—Ä–æ–≥–∏ (THRESHOLDS)")
        print("  - –£–ª—É—á—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –ø–æ—Ä–æ–≥–∏
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {MODEL_FILE}...")
    model_data = {
        "pipeline": pipeline,
        "thresholds": THRESHOLDS,
        "labels": LABELS
    }
    joblib.dump(model_data, MODEL_FILE)
    print("‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    
    print("\n" + "=" * 70)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–ú–æ–¥–µ–ª—å: {MODEL_FILE}")
    print("=" * 70)


if __name__ == "__main__":
    main()

